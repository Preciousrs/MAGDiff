{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66e41db8-1b99-4051-ae23-c8021767d0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import re\n",
    "import random\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import json\n",
    "import itertools\n",
    "import time\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import PIL\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "\n",
    "from diffusers import AutoencoderKL, DDPMScheduler, UNet2DConditionModel, ControlNetModel, StableDiffusionControlNetPipeline, DDIMScheduler\n",
    "\n",
    "\n",
    "from ip_adapter.utils import is_torch2_available\n",
    "\n",
    "import torch.utils.checkpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pipe_infer import StableDiffusionInstantIDPipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14059306-2034-428b-b7dc-686c32142dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_name_or_path =\"models/Realistic_Vision_V4.0_noVAE\"\n",
    "\n",
    "ip_ckpt = \"{checkpoint}\" \n",
    "\n",
    "adapter = ip_ckpt + \"/pytorch_model.bin\"\n",
    "controlnet_path =  ip_ckpt + \"/controlnet\"\n",
    "\n",
    "\n",
    "# Load pipeline\n",
    "controlnet = ControlNetModel.from_pretrained(controlnet_path, torch_dtype=torch.float16)\n",
    "\n",
    "base_model_path =pretrained_model_name_or_path\n",
    "    \n",
    "pipe =  StableDiffusionInstantIDPipeline.from_pretrained(\n",
    "        base_model_path,\n",
    "        controlnet=controlnet,\n",
    "        torch_dtype=torch.float16,\n",
    "    )\n",
    "\n",
    "pipe.cuda()\n",
    "pipe.load_ip_adapter_instantid(adapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4565b2a6-c58c-4385-8be3-19d29723a9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "contour_image = Image.open(\"{contour_image_path}\")\n",
    "\n",
    "ori_wide,ori_heigh = contour_image.size\n",
    "contour_image = contour_image.resize((256,256))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2338,
   "id": "c8bd0f4f-01ae-4ea7-a791-65c4347c178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import cv2\n",
    "\n",
    "def random_crop_with_outline(image_path, outline_path, output_path):\n",
    "    # 读取图像和轮廓图\n",
    "    image = cv2.imread(image_path)\n",
    "    outline = cv2.imread(outline_path)\n",
    "\n",
    "    # 将轮廓图转换为灰度图\n",
    "    gray_outline = cv2.cvtColor(outline, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 应用二值化以获取轮廓区域\n",
    "    _, binary_outline = cv2.threshold(gray_outline, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # 找到轮廓\n",
    "    contours, _ = cv2.findContours(binary_outline, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # 随机裁剪\n",
    "    crop_size = 100\n",
    "\n",
    "    # 找到所有轮廓的边界框\n",
    "    bboxes = [cv2.boundingRect(contour) for contour in contours]\n",
    "\n",
    "    valid_crops = []\n",
    "\n",
    "    for (x, y, w, h) in bboxes:\n",
    "            # 计算可以裁剪的区域，确保裁剪区域在轮廓内\n",
    "        for i in range(max(0, x), min(x + w - crop_size + 1, image.shape[1] - crop_size + 1)):\n",
    "            for j in range(max(0, y), min(y + h - crop_size + 1, image.shape[0] - crop_size + 1)):\n",
    "                valid_crops.append((i, j))\n",
    "\n",
    "\n",
    "    if valid_crops:\n",
    "        # 随机选择一个有效的裁剪位置\n",
    "        idx = random.randint(0, len(valid_crops) - 1)\n",
    "        x, y = valid_crops[idx]\n",
    "\n",
    "        # 裁剪图像\n",
    "        cropped_image = image[y:y + crop_size, x:x + crop_size]\n",
    "        cv2.imwrite(output_path, cropped_image)\n",
    "        print(f'Cropped image saved: {output_path}')\n",
    "    else:\n",
    "        # print(\"No valid crop found within the contour.\")\n",
    "        center_x = image.shape[1] // 2\n",
    "        center_y = image.shape[0] // 2\n",
    "\n",
    "            # 计算裁剪区域的起始点\n",
    "        x = max(center_x - crop_size // 2, 0)\n",
    "        y = max(center_y - crop_size // 2, 0)\n",
    "\n",
    "            # 确保裁剪区域不超出图像边界\n",
    "        x = min(x, image.shape[1] - crop_size)\n",
    "        y = min(y, image.shape[0] - crop_size)\n",
    "\n",
    "            # 裁剪图像\n",
    "        cropped_image = image[y:y + crop_size, x:x + crop_size]\n",
    "        cv2.imwrite(output_path, cropped_image)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469e7cbf-fa4f-40cc-98a6-7a61af0ece36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomcrop\n",
    "\n",
    "outline_path = \"{contour_image_path}\"\n",
    "image_path = \"{image_path}\"\n",
    "# out = \"pamtrain_lossft_crop_out/top_crop_2.png\"\n",
    "out = \"crop.png\"\n",
    "\n",
    "\n",
    "# out = \"crop.png\"\n",
    "\n",
    "random_crop_with_outline(image_path, outline_path, out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c5d966-49aa-4f30-9950-cbb88477bc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get colors  38、63\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 读取图像\n",
    "#img = cv2.imread(\"/data/rensisi/InstantID/style/17.jpg\")\n",
    "img = cv2.imread(\"{image_path}\")\n",
    "\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# 将图像转换为2D数组\n",
    "pixels = img.reshape(-1, 3)\n",
    "\n",
    "# 使用K-means聚类算法提取前5种颜色\n",
    "kmeans = KMeans(n_clusters=5, random_state=0).fit(pixels)\n",
    "colors = kmeans.cluster_centers_.astype(np.uint8)\n",
    "\n",
    "# 创建新的图像\n",
    "size = 128\n",
    "new_img = np.zeros((size, size, 3), dtype=np.uint8)\n",
    "\n",
    "# 在新图像上绘制色条\n",
    "for i in range(5):\n",
    "    new_img[:, i*(size//5):(i+1)*(size//5)] = colors[i]\n",
    "img = new_img\n",
    "plt.imshow(new_img)\n",
    "plt.axis('off')  # 隐藏轴\n",
    "plt.show()\n",
    "# 保存新的图像\n",
    "# 保存新的图像\n",
    "cv2.imwrite(\"color.png\", cv2.cvtColor(new_img, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581a3609-d8c1-4f0a-92b0-9255e376ea94",
   "metadata": {},
   "source": [
    "text+colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af254fae-ab04-44f2-9075-d573a7b139c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seed = random.randint(100, 2**10)\n",
    "# seed = 415\n",
    "print(seed)\n",
    "\n",
    "prompt = \"French floral chiffon dress,no background,high quality\"  \n",
    "  \n",
    "n_prompt = \"(lowres, low quality, worst quality:1.2), (text:1.2), watermark, painting, drawing, illustration, glitch, deformed, mutated, cross-eyed, ugly, disfigured (lowres, low quality, worst quality:1.2), (text:1.2), watermark, painting, drawing, illustration, glitch,deformed, mutated, cross-eyed, ugly, disfigured\"\n",
    "\n",
    "generator = torch.Generator(device=\"cpu\").manual_seed(seed)  \n",
    "\n",
    "pipe.set_ip_adapter_scale(0.8) \n",
    "image =  pipe(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=n_prompt,\n",
    "            image_embeds=img,\n",
    "            image=contour_image,\n",
    "            controlnet_conditioning_scale=0.0,\n",
    "            num_inference_steps=30,\n",
    "            guidance_scale=8, \n",
    "            generator=generator,\n",
    "            ).images[0]\n",
    "\n",
    "image "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce88f7b-af09-4e9b-a93e-5cc3fd54be2c",
   "metadata": {},
   "source": [
    "sketch+crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbb4041-0cc9-4829-aa69-2b160b3985ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seed = random.randint(400, 2**10)\n",
    "seed= 1020\n",
    "\n",
    "print(\"seed:\" , seed)\n",
    "prompt = \"Casual style jacket\" \n",
    "n_prompt = \"(lowres, low quality, worst quality:1.2), (text:1.2), watermark, painting, drawing, illustration, glitch, deformed, mutated, cross-eyed, ugly, disfigured (lowres, low quality, worst quality:1.2), (text:1.2), watermark, painting, drawing, illustration, glitch,deformed, mutated, cross-eyed, ugly, disfigured\"\n",
    "\n",
    "generator = torch.Generator(device=\"cpu\").manual_seed(seed) \n",
    "#\n",
    "pipe.set_ip_adapter_scale(0.8) \n",
    "image =  pipe(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=n_prompt,\n",
    "            image_embeds=img,\n",
    "            image=contour_image,\n",
    "            controlnet_conditioning_scale=0.9,\n",
    "            num_inference_steps=30,\n",
    "            guidance_scale=5, \n",
    "            generator=generator,\n",
    "            ).images[0]\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ced9143-61da-4d70-b9b8-a96b69a5e953",
   "metadata": {},
   "source": [
    "text + crop + contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74525ec-1d21-4d2a-b2b8-4e930fc15df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seed = random.randint(100, 2**10)\n",
    "seed = 869\n",
    "print(seed)\n",
    "prompt = \"Tie-dye, bohemian style t-shirt,high quality.\"  #\n",
    "n_prompt = \"(lowres, low quality, worst quality:1.2), (text:1.2), watermark, painting, drawing, illustration, glitch, deformed, mutated, cross-eyed, ugly, disfigured (lowres, low quality, worst quality:1.2), (text:1.2), watermark, painting, drawing, illustration, glitch,deformed, mutated, cross-eyed, ugly, disfigured\"\n",
    "\n",
    "generator = torch.Generator(device=\"cpu\").manual_seed(seed)  \n",
    "\n",
    "pipe.set_ip_adapter_scale(0.8)\n",
    "image =  pipe(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=n_prompt,\n",
    "            image_embeds=img,\n",
    "            image=contour_image,\n",
    "            controlnet_conditioning_scale=0.7,\n",
    "            num_inference_steps=30,\n",
    "            guidance_scale=6, \n",
    "            generator=generator,\n",
    "            ).images[0]\n",
    "#all train\n",
    "\n",
    "\n",
    "image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
